{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abdul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abdul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re  # Import regex module for text processing\n",
    "import os  # Import os module for file and directory management\n",
    "import numpy as np  # Import NumPy for numerical operations\n",
    "import pandas as pd  # Import pandas for data manipulation and analysis\n",
    "import torch  # Import PyTorch for deep learning tasks\n",
    "from transformers import AutoTokenizer, AutoModel  # Import Hugging Face transformers for NLP models and tokenizers\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # Import cosine similarity function for comparing sentence embeddings\n",
    "from nltk.corpus import stopwords  # Import stopwords from NLTK for text preprocessing\n",
    "from nltk.tokenize import word_tokenize  # Import word_tokenize from NLTK for tokenizing sentences\n",
    "import nltk  # Import Natural Language Toolkit (NLTK) for NLP tasks\n",
    "\n",
    "nltk.download('stopwords')  # Download stopwords from NLTK\n",
    "nltk.download('punkt')  # Download punkt tokenizer from NLTK"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This code defines a class `EmojifyAI` that suggests emojis based on the input sentence. It uses a pre-trained BERT model to calculate sentence embeddings and find similarity between the input sentence and emojis' descriptions. The class also includes methods to process sentences, tokenize, and compute embeddings for sentences and emojis' descriptions. Finally, it has methods to generate and save an emoji data CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmojifyAI:  # Define the EmojifyAI class for suggesting emojis\n",
    "    def __init__(self):  # Initialize the class and load the model\n",
    "        self.load_model()\n",
    "\n",
    "    def load_model(self):  # Load the pre-trained BERT model for sentence embeddings\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "        self.model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "\n",
    "    def process_sentence(self, sentence):  # Preprocess and tokenize input sentence\n",
    "        sentence = sentence.lower()  # Convert sentence to lowercase\n",
    "        sentence = re.sub('[^a-z]+', ' ', sentence)  # Remove non-letter characters\n",
    "        stop_words = set(stopwords.words('english'))  # Define English stopwords\n",
    "        word_tokens = word_tokenize(sentence)  # Tokenize sentence\n",
    "        sentence = [w for w in word_tokens if not w.lower() in stop_words]  # Remove stopwords\n",
    "        sentence = ' '.join(sentence)  # Join tokens to form processed sentence\n",
    "        return self.get_mean_tokens([sentence])  # Return mean tokens for the processed sentence\n",
    "\n",
    "    def process_csv(self):  # Process and filter emoji descriptions from CSV file\n",
    "        self.emoji_df = pd.read_csv(\"data/emoji-data.csv\")  # Read the emoji data CSV\n",
    "        self.all_emoji_df = self.emoji_df  # Store all emoji data\n",
    "        self.emoji_df = self.emoji_df[1800:2000]  # Select a subset of emoji data\n",
    "        self.emoji_df = self.emoji_df.reset_index(drop=True)  # Reset index\n",
    "        return self.get_mean_tokens(self.emoji_df['description'])  # Return mean tokens for emoji descriptions\n",
    "\n",
    "    def get_mean_tokens(self, sentences):  # Calculate mean tokens for sentences\n",
    "        self.obtain_tokens(sentences)  # Obtain tokens for sentences\n",
    "        self.compute_embeddings()  # Compute embeddings for tokens\n",
    "        return self.calculate_mean_value()  # Calculate and return mean values of embeddings\n",
    "\n",
    "    def obtain_tokens(self, sentences):  # Tokenize input sentences\n",
    "        self.tokens = {'input_ids': [], 'attention_mask': []}  # Initialize token dictionaries\n",
    "\n",
    "        for sentence in sentences:  # Iterate through sentences\n",
    "            new_tokens = self.tokenizer.encode_plus(sentence, max_length=128,\n",
    "                                                    truncation=True, padding='max_length',\n",
    "                                                    return_tensors='pt')  # Tokenize sentence\n",
    "            self.tokens['input_ids'].append(new_tokens['input_ids'][0])  # Append input_ids\n",
    "            self.tokens['attention_mask'].append(new_tokens['attention_mask'][0])  # Append attention_mask\n",
    "\n",
    "        self.tokens['input_ids'] = torch.stack(self.tokens['input_ids'])  # Stack input_ids\n",
    "        self.tokens['attention_mask'] = torch.stack(self.tokens['attention_mask'])  # Stack attention_mask\n",
    "\n",
    "    def compute_embeddings(self):  # Compute embeddings for tokens\n",
    "        outputs = self.model(**self.tokens)  # Forward pass through the model\n",
    "        self.embeddings = outputs.last_hidden_state  # Extract embeddings\n",
    "\n",
    "    def calculate_mean_value(self):  # Calculate mean values of embeddings\n",
    "        attention_mask = self.tokens['attention_mask']  # Retrieve attention_mask\n",
    "        mask = attention_mask.unsqueeze(-1).expand(self.embeddings.size()).float()  # Create mask\n",
    "        masked_embeddings = self.embeddings * mask  # Apply mask to embeddings\n",
    "        summed = torch.sum(masked_embeddings, 1)  # Sum masked embeddings\n",
    "        summed_mask = torch.clamp(mask.sum(1), min=1e-9)  # Sum mask values\n",
    "        self.mean_pooled = summed / summed_mask  # Calculate mean pooled embeddings\n",
    "        self.mean_pooled = self.mean_pooled.detach().numpy()  # Convert to numpy array\n",
    "        return self.mean_pooled  # Return mean pooled embeddings\n",
    "\n",
    "    def find_similarity(self, sentence_tokens, mean_tokens):  # Find similarity between sentence and emoji tokens\n",
    "        similarity = cosine_similarity([sentence_tokens], mean_tokens)  # Calculate cosine similarity\n",
    "        return similarity  # Return similarity\n",
    "\n",
    "    def generate_emoji_csv(self):  # Generate emoji data CSV file\n",
    "        df = pd.read_csv(\"data/raw-emoji-data.csv\", usecols=[1, 3], header=None)  # Read raw emoji data CSV\n",
    "        df = df.dropna()  # Drop rows with missing values\n",
    "        df = df.iloc[1:, :]  # Select all rows except the header\n",
    "        self.save_csv(df)  # Save processed data as CSV\n",
    "\n",
    "    def save_csv(self, df):  # Save emoji data to CSV file\n",
    "        df = pd.DataFrame({'emoji': df[1], 'description': df[3]})  # Create a DataFrame with emoji and description\n",
    "        df.to_csv(\"data/emoji-data.csv\", encoding='utf-8', index=False)  # Save DataFrame as CSV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code demonstrates how to use the EmojifyAI class to suggest emojis for a given sentence. It starts by creating an instance of the class, generating an emoji CSV file, and processing the CSV to obtain mean tokens for emojis. Then, it defines an example sentence, processes it, and finds the similarity between the sentence and emojis. It prints the top 5 most similar emojis and their descriptions. Finally, it defines a suggestEmojis function that takes a sentence as input and suggests emojis based on the similarity between the sentence and emojis' descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_rec = EmojifyAI() # Instantiate the EmojifyAI class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_rec.generate_emoji_csv() # Generate the emoji data CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 768)\n"
     ]
    }
   ],
   "source": [
    "mean_tokens = emoji_rec.process_csv() # Process the CSV and obtain mean tokens for emojis\n",
    "print(mean_tokens.shape) # Print the shape of the mean tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentence = \"Do you play games?\" # Define an example sentence\n",
    "sentence_token = emoji_rec.process_sentence(example_sentence) # Process the example sentence\n",
    "similarity = emoji_rec.find_similarity(sentence_token[0], mean_tokens) # Find the similarity between the sentence and emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 ğŸ‡¿ğŸ‡¼ flag: Zimbabwe\n",
      "0 ğŸ‡»ğŸ‡ª flag: Venezuela\n",
      "15 ğŸ´ó §ó ¢ó ·ó ¬ó ³ó ¿ flag: Wales\n",
      "13 ğŸ´ó §ó ¢ó ¥ó ®ó §ó ¿ flag: England\n",
      "4 ğŸ‡»ğŸ‡º flag: Vanuatu\n"
     ]
    }
   ],
   "source": [
    "top_indices = (-similarity[0]).argsort()[:5] # Get the indices of the top 5 most similar emojis\n",
    "for i in top_indices: # Iterate through the top indices\n",
    "    print(i, emoji_rec.emoji_df['emoji'][i], emoji_rec.emoji_df['description'][i]) # Print the index, emoji, and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run 1 time\n",
    "# torch.save(mean_tokens, 'checkpoint/token-all.pt') # Save the mean tokens to a file named 'token-all.pt' in the 'checkpoint' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggestEmojis(sentence): # Define the suggestEmojis function\n",
    "    name = 'token-all.pt' # Define the name of the token file\n",
    "    all_tokens = torch.load('checkpoint/'+name) # Load the precomputed tokens\n",
    "    sentence_token = emoji_rec.process_sentence(sentence) # Process the input sentence\n",
    "    similarity = emoji_rec.find_similarity(sentence_token[0], all_tokens) # Find the similarity between the sentence and emojis\n",
    "    indices = (-similarity[0]).argsort()[:5] # Get the indices of the top 5 most similar emojis\n",
    "    emoji_df = pd.read_csv(\"data/emoji-data.csv\") # Read the emoji data CSV file\n",
    "    for j in indices: # Iterate through the top indices\n",
    "        print(emoji_df['emoji'][j], emoji_df['description'][j]) # Print the emoji and its description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example - 1\n",
      "I am going to the movies\n",
      "Following are the suggested emojis:\n",
      "-----------------\n",
      "ğŸ¥ movie camera\n",
      "ğŸ¦ cinema\n",
      "ğŸ“½ film projector\n",
      "ğŸ“€ dvd\n",
      "ğŸ film frames\n"
     ]
    }
   ],
   "source": [
    "print(\"Example - 1\")\n",
    "test_sentence1 = \"I am going to the movies\"\n",
    "print(test_sentence1)\n",
    "print(\"Following are the suggested emojis:\\n-----------------\")\n",
    "suggestEmojis(test_sentence1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example - 2\n",
      "I love eating pizza\n",
      "Following are the suggested emojis:\n",
      "-----------------\n",
      "ğŸ• pizza\n",
      "ğŸ˜‹ face savoring food\n",
      "ğŸŸ french fries\n",
      "ğŸ” hamburger\n",
      "ğŸŒ® taco\n"
     ]
    }
   ],
   "source": [
    "print(\"Example - 2\")\n",
    "test_sentence2 = \"I love eating pizza\"\n",
    "print(test_sentence2)\n",
    "print(\"Following are the suggested emojis:\\n-----------------\")\n",
    "suggestEmojis(test_sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example - 3\n",
      "The weather is sunny today\n",
      "Following are the suggested emojis:\n",
      "-----------------\n",
      "â˜€ sun\n",
      "ğŸ˜ beaming face with smiling eyes\n",
      "ğŸŒ sun with face\n",
      "ğŸŒ¤ sun behind small cloud\n",
      "â›… sun behind cloud\n"
     ]
    }
   ],
   "source": [
    "print(\"Example - 3\")\n",
    "test_sentence3 = \"The weather is sunny today\"\n",
    "print(test_sentence3)\n",
    "print(\"Following are the suggested emojis:\\n-----------------\")\n",
    "suggestEmojis(test_sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example - 4\n",
      "I am feeling tired and sleepy\n",
      "Following are the suggested emojis:\n",
      "-----------------\n",
      "ğŸ˜« tired face\n",
      "ğŸ˜ª sleepy face\n",
      "ğŸ˜© weary face\n",
      "ğŸ˜ disappointed face\n",
      "ğŸ™ slightly frowning face\n"
     ]
    }
   ],
   "source": [
    "print(\"Example - 4\")\n",
    "test_sentence4 = \"I am feeling tired and sleepy\"\n",
    "print(test_sentence4)\n",
    "print(\"Following are the suggested emojis:\\n-----------------\")\n",
    "suggestEmojis(test_sentence4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example - 5\n",
      "My favorite sport is soccer\n",
      "Following are the suggested emojis:\n",
      "-----------------\n",
      "âš½ soccer ball\n",
      "ğŸ¤Ÿ love you gesture\n",
      "ğŸ‘©â€â¤ï¸â€ğŸ‘© couple with heart woman woman\n",
      "ğŸ˜ smiling face with heart eyes\n",
      "âœŒ victory hand\n"
     ]
    }
   ],
   "source": [
    "print(\"Example - 5\")\n",
    "test_sentence5 = \"My favorite sport is soccer\"\n",
    "print(test_sentence5)\n",
    "print(\"Following are the suggested emojis:\\n-----------------\")\n",
    "suggestEmojis(test_sentence5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example - 6\n",
      "Let's go to the beach this weekend\n",
      "Following are the suggested emojis:\n",
      "-----------------\n",
      "ğŸ– beach with umbrella\n",
      "ğŸ• camping\n",
      "ğŸŒ‡ sunset\n",
      "â˜€ sun\n",
      "ğŸ¦ª oyster\n"
     ]
    }
   ],
   "source": [
    "print(\"Example - 6\")\n",
    "test_sentence6 = \"Let's go to the beach this weekend\"\n",
    "print(test_sentence6)\n",
    "print(\"Following are the suggested emojis:\\n-----------------\")\n",
    "suggestEmojis(test_sentence6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example - 7\n",
      "I am so excited for the party tonight\n",
      "Following are the suggested emojis:\n",
      "-----------------\n",
      "ğŸ¥³ partying face\n",
      "ğŸ‰ party popper\n",
      "ğŸ‘ clapping hands\n",
      "ğŸ”† bright button\n",
      "ğŸ’– sparkling heart\n"
     ]
    }
   ],
   "source": [
    "print(\"Example - 7\")\n",
    "test_sentence7 = \"I am so excited for the party tonight\"\n",
    "print(test_sentence7)\n",
    "print(\"Following are the suggested emojis:\\n-----------------\")\n",
    "suggestEmojis(test_sentence7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example - 8\n",
      "I am working on a new project at my job\n",
      "Following are the suggested emojis:\n",
      "-----------------\n",
      "ğŸ‘· construction worker\n",
      "ğŸ†• new button\n",
      "ğŸ§‘â€ğŸ­ factory worker\n",
      "ğŸš§ construction\n",
      "ğŸ— building construction\n"
     ]
    }
   ],
   "source": [
    "print(\"Example - 8\")\n",
    "test_sentence8 = \"I am working on a new project at my job\"\n",
    "print(test_sentence8)\n",
    "print(\"Following are the suggested emojis:\\n-----------------\")\n",
    "suggestEmojis(test_sentence8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example - 9\n",
      "My dog loves to play fetch\n",
      "Following are the suggested emojis:\n",
      "-----------------\n",
      "ğŸ© poodle\n",
      "ğŸ¦® guide dog\n",
      "ğŸ• dog\n",
      "ğŸ¶ dog face\n",
      "ğŸ•â€ğŸ¦º service dog\n"
     ]
    }
   ],
   "source": [
    "print(\"Example - 9\")\n",
    "test_sentence9 = \"My dog loves to play fetch\"\n",
    "print(test_sentence9)\n",
    "print(\"Following are the suggested emojis:\\n-----------------\")\n",
    "suggestEmojis(test_sentence9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example - 10\n",
      "The traffic is terrible during rush hour\n",
      "Following are the suggested emojis:\n",
      "-----------------\n",
      "ğŸ‘¿ angry face with horns\n",
      "ğŸŒ foggy\n",
      "ğŸ˜  angry face\n",
      "ğŸ˜± face screaming in fear\n",
      "ğŸ˜¨ fearful face\n"
     ]
    }
   ],
   "source": [
    "print(\"Example - 10\")\n",
    "test_sentence10 = \"The traffic is terrible during rush hour\"\n",
    "print(test_sentence10)\n",
    "print(\"Following are the suggested emojis:\\n-----------------\")\n",
    "suggestEmojis(test_sentence10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
